{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import normalize\n",
    "from scipy.misc import imresize\n",
    "# import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exist, images will be written in asme folder\n",
      "GAN-EMN00bay.png is not converted\n",
      "GAN-EMN00bed.png is not converted\n",
      "GAN-EMN00bin.png is not converted\n",
      "GAN-EMN00car.png is not converted\n",
      "GAN-EMN00cat.png is not converted\n",
      "GAN-EMN00dig.png is not converted\n",
      "GAN-EMN00dog.png is not converted\n",
      "GAN-EMN00fan.png is not converted\n",
      "GAN-EMN00key.png is not converted\n",
      "GAN-EMN00mat.png is not converted\n",
      "GAN-EMN00mug.png is not converted\n",
      "GAN-EMN00net.png is not converted\n",
      "GAN-EMN00pan.png is not converted\n",
      "GAN-EMN00pig.png is not converted\n",
      "GAN-EMN00pin.png is not converted\n",
      "GAN-EMN00rat.png is not converted\n",
      "GAN-EMN00red.png is not converted\n",
      "GAN-EMN00run.png is not converted\n",
      "GAN-EMN00say.png is not converted\n",
      "GAN-EMN00sun.png is not converted\n",
      "GAN-EMN00tab.png is not converted\n",
      "GAN-EMN00ten.png is not converted\n",
      "GAN-EMN00the.png is not converted\n",
      "GAN-EMN00tin.png is not converted\n",
      "GAN-EMN00too.png is not converted\n",
      "GAN-EMN00wet.png is not converted\n",
      "GAN-EMN00win.png is not converted\n",
      "GAN-EMN00yet.png is not converted\n",
      "GAN-EMN00zip.png is not converted\n",
      "GAN-EMN00zoo.png is not converted\n",
      "GAN-EMN01bay.png is not converted\n",
      "GAN-EMN01bed.png is not converted\n",
      "GAN-EMN01bin.png is not converted\n",
      "GAN-EMN01car.png is not converted\n",
      "GAN-EMN01cat.png is not converted\n",
      "GAN-EMN01dig.png is not converted\n",
      "GAN-EMN01dog.png is not converted\n",
      "GAN-EMN01fan.png is not converted\n",
      "GAN-EMN01key.png is not converted\n",
      "GAN-EMN01mat.png is not converted\n",
      "GAN-EMN01mug.png is not converted\n",
      "GAN-EMN01net.png is not converted\n",
      "GAN-EMN01pan.png is not converted\n",
      "GAN-EMN01pig.png is not converted\n",
      "GAN-EMN01pin.png is not converted\n",
      "GAN-EMN01rat.png is not converted\n",
      "GAN-EMN01red.png is not converted\n",
      "GAN-EMN01run.png is not converted\n",
      "GAN-EMN01say.png is not converted\n",
      "GAN-EMN01sun.png is not converted\n",
      "GAN-EMN01tab.png is not converted\n",
      "GAN-EMN01ten.png is not converted\n",
      "GAN-EMN01the.png is not converted\n",
      "GAN-EMN01tin.png is not converted\n",
      "GAN-EMN01too.png is not converted\n",
      "GAN-EMN01wet.png is not converted\n",
      "GAN-EMN01win.png is not converted\n",
      "GAN-EMN01yet.png is not converted\n",
      "GAN-EMN01zip.png is not converted\n",
      "GAN-EMN01zoo.png is not converted\n",
      "GAN-EMN02bay.png is not converted\n",
      "GAN-EMN02bed.png is not converted\n",
      "GAN-EMN02bin.png is not converted\n",
      "GAN-EMN02car.png is not converted\n",
      "GAN-EMN02cat.png is not converted\n",
      "GAN-EMN02dig.png is not converted\n",
      "GAN-EMN02dog.png is not converted\n",
      "GAN-EMN02fan.png is not converted\n",
      "GAN-EMN02key.png is not converted\n",
      "GAN-EMN02mat.png is not converted\n",
      "GAN-EMN02mug.png is not converted\n",
      "GAN-EMN02net.png is not converted\n",
      "GAN-EMN02pan.png is not converted\n",
      "GAN-EMN02pig.png is not converted\n",
      "GAN-EMN02pin.png is not converted\n",
      "GAN-EMN02rat.png is not converted\n",
      "GAN-EMN02red.png is not converted\n",
      "GAN-EMN02run.png is not converted\n",
      "GAN-EMN02say.png is not converted\n",
      "GAN-EMN02sun.png is not converted\n",
      "GAN-EMN02tab.png is not converted\n",
      "GAN-EMN02ten.png is not converted\n",
      "GAN-EMN02the.png is not converted\n",
      "GAN-EMN02tin.png is not converted\n",
      "GAN-EMN02too.png is not converted\n",
      "GAN-EMN02wet.png is not converted\n",
      "GAN-EMN02win.png is not converted\n",
      "GAN-EMN02yet.png is not converted\n",
      "GAN-EMN02zip.png is not converted\n",
      "GAN-EMN02zoo.png is not converted\n",
      "GAN-EMN03bay.png is not converted\n",
      "GAN-EMN03bed.png is not converted\n",
      "GAN-EMN03bin.png is not converted\n",
      "GAN-EMN03car.png is not converted\n",
      "GAN-EMN03cat.png is not converted\n",
      "GAN-EMN03dig.png is not converted\n",
      "GAN-EMN03dog.png is not converted\n",
      "GAN-EMN03fan.png is not converted\n",
      "GAN-EMN03key.png is not converted\n",
      "GAN-EMN03mat.png is not converted\n",
      "GAN-EMN03mug.png is not converted\n",
      "GAN-EMN03net.png is not converted\n",
      "GAN-EMN03pan.png is not converted\n",
      "GAN-EMN03pig.png is not converted\n",
      "GAN-EMN03pin.png is not converted\n",
      "GAN-EMN03rat.png is not converted\n",
      "GAN-EMN03red.png is not converted\n",
      "GAN-EMN03run.png is not converted\n",
      "GAN-EMN03say.png is not converted\n",
      "GAN-EMN03sun.png is not converted\n",
      "GAN-EMN03tab.png is not converted\n",
      "GAN-EMN03ten.png is not converted\n",
      "GAN-EMN03the.png is not converted\n",
      "GAN-EMN03tin.png is not converted\n",
      "GAN-EMN03too.png is not converted\n",
      "GAN-EMN03wet.png is not converted\n",
      "GAN-EMN03win.png is not converted\n",
      "GAN-EMN03yet.png is not converted\n",
      "GAN-EMN03zip.png is not converted\n",
      "GAN-EMN03zoo.png is not converted\n",
      "GAN-EMN04bay.png is not converted\n",
      "GAN-EMN04bed.png is not converted\n",
      "GAN-EMN04bin.png is not converted\n",
      "GAN-EMN04car.png is not converted\n",
      "GAN-EMN04cat.png is not converted\n",
      "GAN-EMN04dig.png is not converted\n",
      "GAN-EMN04dog.png is not converted\n",
      "GAN-EMN04fan.png is not converted\n",
      "GAN-EMN04key.png is not converted\n",
      "GAN-EMN04mat.png is not converted\n",
      "GAN-EMN04mug.png is not converted\n",
      "GAN-EMN04net.png is not converted\n",
      "GAN-EMN04pan.png is not converted\n",
      "GAN-EMN04pig.png is not converted\n",
      "GAN-EMN04pin.png is not converted\n",
      "GAN-EMN04rat.png is not converted\n",
      "GAN-EMN04red.png is not converted\n",
      "GAN-EMN04run.png is not converted\n",
      "GAN-EMN04say.png is not converted\n",
      "GAN-EMN04sun.png is not converted\n",
      "GAN-EMN04tab.png is not converted\n",
      "GAN-EMN04ten.png is not converted\n",
      "GAN-EMN04the.png is not converted\n",
      "GAN-EMN04tin.png is not converted\n",
      "GAN-EMN04too.png is not converted\n",
      "GAN-EMN04wet.png is not converted\n",
      "GAN-EMN04win.png is not converted\n",
      "GAN-EMN04yet.png is not converted\n",
      "GAN-EMN04zip.png is not converted\n",
      "GAN-EMN04zoo.png is not converted\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "\n",
    "path = 'EMNIST_Real/' # Source Folder\n",
    "dstpath = 'EMNIST_Real/GRAYSCALE' # Destination Folder\n",
    "\n",
    "try:\n",
    "    makedirs(dstpath)\n",
    "except:\n",
    "    print (\"Directory already exist, images will be written in asme folder\")#\n",
    "\n",
    "# Folder won't used\n",
    "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
    "\n",
    "for image in files:\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join(path,image))\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        dstPath = join(dstpath,image)\n",
    "        cv2.imwrite(dstPath,gray)\n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_image_id('EMNIST_Real/GRAYSCALE/GAN-EMN00bed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = glob.glob('EMNIST_Real/*.png')\n",
    "forged_images = glob.glob('./EMNIST_Fake50Epochs/*.png')\n",
    "\n",
    "#C:\\Users\\erint\\handwriting project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMNIST_Real\\\\GAN-EMN00bay.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00bed.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00bin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00car.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00cat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00dig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00dog.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00fan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00key.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00mat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00mug.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00net.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00pan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00pig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00pin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00rat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00red.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00run.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00say.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00sun.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00tab.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00ten.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00the.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00tin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00too.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00wet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00win.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00yet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00zip.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN00zoo.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01bay.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01bed.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01bin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01car.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01cat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01dig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01dog.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01fan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01key.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01mat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01mug.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01net.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01pan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01pig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01pin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01rat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01red.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01run.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01say.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01sun.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01tab.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01ten.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01the.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01tin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01too.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01wet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01win.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01yet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01zip.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN01zoo.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02bay.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02bed.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02bin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02car.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02cat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02dig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02dog.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02fan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02key.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02mat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02mug.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02net.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02pan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02pig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02pin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02rat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02red.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02run.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02say.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02sun.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02tab.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02ten.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02the.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02tin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02too.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02wet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02win.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02yet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02zip.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN02zoo.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03bay.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03bed.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03bin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03car.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03cat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03dig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03dog.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03fan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03key.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03mat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03mug.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03net.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03pan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03pig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03pin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03rat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03red.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03run.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03say.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03sun.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03tab.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03ten.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03the.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03tin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03too.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03wet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03win.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03yet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03zip.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN03zoo.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04bay.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04bed.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04bin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04car.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04cat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04dig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04dog.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04fan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04key.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04mat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04mug.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04net.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04pan.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04pig.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04pin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04rat.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04red.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04run.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04say.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04sun.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04tab.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04ten.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04the.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04tin.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04too.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04wet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04win.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04yet.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04zip.png',\n",
       " 'EMNIST_Real\\\\GAN-EMN04zoo.png']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(image_path):\n",
    "    \"\"\"returns image ID from the image path\"\"\"\n",
    "    image_id = image_path.split('/')[-1].split('.')[0][-3:]\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bay'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_id('EMNIST_Real/GRAYSCALE/GAN-EMN00bay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store all images.\n",
    "real_images_dict = defaultdict(list)\n",
    "forged_images_dict = defaultdict(list)\n",
    "\n",
    "# Iterate over real images and put them in dictionary values for same image_id key.\n",
    "for real_image, forged_image in zip(real_images, forged_images):\n",
    "    \n",
    "    # add image to dictionary\n",
    "    real_image_id = get_image_id(real_image)\n",
    "    real_images_dict[real_image_id].append(real_image)\n",
    "    \n",
    "    forged_image_id = get_image_id(forged_image)\n",
    "    forged_images_dict[forged_image_id].append(forged_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_image_tuples = list()\n",
    "# positive_image_tuples = list()\n",
    "\n",
    "for image_id in real_images_dict.keys():\n",
    "    real = real_images_dict[image_id]\n",
    "    forged = forged_images_dict[image_id]\n",
    "    \n",
    "    negative_image_tuples.extend(list(itertools.product(real, real, forged)))\n",
    "#     positive_image_tuples.extend(list(itertools.product(real, real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image_path, size=(28, 84)):\n",
    "    \"\"\"returns processed images\"\"\"\n",
    "    # Open image and convert to grayscale.\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"L\")\n",
    "    \n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Resize image to 128, 256 using bilinear interpolation.\n",
    "    # image_array_processed = imresize(image_array, size=size, interp='bilinear')\n",
    "    \n",
    "    # Invert pixel values.\n",
    "    image_array_processed = 1 - image_array\n",
    "    \n",
    "    # Normalize by dividing pixel values with standard deviation.\n",
    "    image_array_processed = image_array_processed / np.std(image_array_processed)\n",
    "    \n",
    "    # Expand dimension to (200, 220, 1)\n",
    "    image_array_processed = np.expand_dims(image_array_processed, axis=2)\n",
    "    \n",
    "    return image_array_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data\n",
    "image_1 = []\n",
    "image_2 = []\n",
    "image_3 = []\n",
    "labels = []\n",
    "\n",
    "for anchor, positive, negative in negative_image_tuples[:1000]:\n",
    "    image_1.append(process(anchor))\n",
    "    image_2.append(process(positive))\n",
    "    image_3.append(process(negative))\n",
    "    labels.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to numpy arrays\n",
    "image_1_array = np.asarray(image_1)\n",
    "image_2_array = np.asarray(image_2)\n",
    "image_3_array = np.asarray(image_3)\n",
    "labels_array = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle numpy arrays\n",
    "idx = np.random.choice(range(len(image_1)), size=len(image_1), replace=False)\n",
    "\n",
    "X_1 = image_1_array[idx]\n",
    "X_2 = image_2_array[idx]\n",
    "X_3 = image_3_array[idx]\n",
    "y = labels_array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-valid-test set.\n",
    "train_split = 0.8\n",
    "valid_split = 0.9\n",
    "train_offset = int(train_split * len(X_1))\n",
    "valid_offset = int(valid_split * len(X_1))\n",
    "\n",
    "X_1_train = X_1[:train_offset]\n",
    "X_2_train = X_2[:train_offset]\n",
    "X_3_train = X_3[:train_offset]\n",
    "y_train = y[:train_offset]\n",
    "\n",
    "X_1_valid = X_1[train_offset:valid_offset]\n",
    "X_2_valid = X_2[train_offset:valid_offset]\n",
    "X_3_valid = X_3[train_offset:valid_offset]\n",
    "y_valid = y[train_offset:valid_offset]\n",
    "\n",
    "X_1_test = X_1[valid_offset:]\n",
    "X_2_test = X_2[valid_offset:]\n",
    "X_3_test = X_3[valid_offset:]\n",
    "y_test = y[valid_offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 28, 84, 1), (100, 28, 84, 1), (100, 28, 84, 1))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train.shape, y_valid.shape, y_test.shape\n",
    "X_1_train.shape, X_1_valid.shape, X_1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "destn_dir = 'DatasetGAN/saved_processed/'\n",
    "np.savez(os.path.join(destn_dir, 'train.npz'), X_1_train=X_1_train, X_2_train=X_2_train, X_3_train=X_3_train, y_train=y_train)\n",
    "np.savez(os.path.join(destn_dir, 'valid.npz'), X_1_valid=X_1_valid, X_2_valid=X_2_valid, X_3_valid=X_3_valid, y_valid=y_valid)\n",
    "np.savez(os.path.join(destn_dir, 'test.npz'), X_1_test=X_1_test, X_2_test=X_2_test, X_3_test=X_3_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'DatasetGAN/saved_processed/'\n",
    "\n",
    "train = np.load(os.path.join(data_path, 'train.npz'))\n",
    "X_1_train=train['X_1_train']\n",
    "X_2_train=train['X_2_train']\n",
    "X_3_train=train['X_3_train']\n",
    "y_train=train['y_train']\n",
    "\n",
    "valid = np.load(os.path.join(data_path, 'valid.npz'))\n",
    "X_1_valid=valid['X_1_valid']\n",
    "X_2_valid=valid['X_2_valid']\n",
    "X_3_valid=valid['X_3_valid']\n",
    "y_valid=valid['y_valid']\n",
    "\n",
    "test = np.load(os.path.join(data_path, 'test.npz'))\n",
    "X_1_test=test['X_1_test']\n",
    "X_2_test=test['X_2_test']\n",
    "X_3_test=test['X_3_test']\n",
    "y_test=test['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 2\n",
    "input_shape = (28, 84, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.1056 - accuracy: 0.9375 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_2_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_2_valid, y_valid))\n",
    "score = model.evaluate(X_2_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 84, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 74, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 18, 74, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 36, 96)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 40, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 36, 256)        614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 36, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 17, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 17, 256)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 5, 19, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 17, 384)        885120    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 5, 19, 384)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 17, 256)        884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 4,627,264\n",
      "Trainable params: 4,626,560\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputTensor = Input((28,84,1))\n",
    "\n",
    "conv1 = layers.Conv2D(filters=96, \n",
    "                      kernel_size=(11,11), \n",
    "                      strides=1, \n",
    "                      activation='relu', \n",
    "                      input_shape=(155, 220, 1), \n",
    "                      data_format=\"channels_last\")(inputTensor)\n",
    "\n",
    "conv1_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv1)\n",
    "\n",
    "conv1_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv1_norm)\n",
    "\n",
    "conv2_padding = layers.ZeroPadding2D((2, 2))(conv1_pool)\n",
    "\n",
    "conv2 = layers.Conv2D(filters=256, \n",
    "                      kernel_size=(5,5), \n",
    "                      strides=1, \n",
    "                      activation='relu')(conv2_padding)\n",
    "\n",
    "conv2_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv2)\n",
    "\n",
    "conv2_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv2_norm)\n",
    "\n",
    "conv2_dropout = layers.Dropout(0.3, seed=1)(conv2_pool)\n",
    "\n",
    "conv3_padding = layers.ZeroPadding2D((1,1))(conv2_dropout)\n",
    "\n",
    "conv3 = layers.Conv2D(filters=384, \n",
    "                      kernel_size=(3,3), \n",
    "                      strides=1, \n",
    "                      activation = 'relu')(conv3_padding)\n",
    "\n",
    "conv4_padding = layers.ZeroPadding2D((1,1))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(filters=256, \n",
    "                      kernel_size=(3,3), \n",
    "                      strides=1, \n",
    "                      activation='relu')(conv4_padding)\n",
    "                                                                    \n",
    "conv4_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv4)\n",
    "                                                                    \n",
    "conv4_dropout = layers.Dropout(0.3, seed=1)(conv4_pool)\n",
    "                                                                    \n",
    "flatten_layer = layers.Flatten()(conv4_dropout)\n",
    "                                                                    \n",
    "fully_connected1 = layers.Dense(1024)(flatten_layer)\n",
    "\n",
    "fc1_dropout = layers.Dropout(0.5, seed=1)(fully_connected1)\n",
    "                                                                    \n",
    "embedding = layers.Dense(128)(fc1_dropout)\n",
    "                                                                    \n",
    "embedding_model = Model(inputs=[inputTensor], \n",
    "                         outputs=embedding, \n",
    "                         name='embedding_model')\n",
    "                                                                    \n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(embeddings):\n",
    "    \"\"\"\n",
    "    calculates triplet loss over inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_a, processed_p, processed_n = embeddings[0], embeddings[1], embeddings[2]\n",
    "    \n",
    "    positive_dist= euclidean_distance_loss(processed_a, processed_p)\n",
    "    negative_dist = euclidean_distance_loss(processed_a, processed_n)\n",
    "       \n",
    "    margin = 0.0\n",
    "    loss = K.maximum(margin, positive_dist - negative_dist)\n",
    "    \n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fake loss function for Keras.\n",
    "    \"\"\"\n",
    "    return y_pred - 0 * y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erint\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_dim=(28,84,1)\n",
    "input_anchor = Input(shape=(in_dim))\n",
    "input_positive = Input(shape=(in_dim))\n",
    "input_negative = Input(shape=(in_dim))\n",
    "embedding_a=embedding_model(input_anchor)\n",
    "embedding_p=embedding_model(input_positive)\n",
    "embedding_n=embedding_model(input_negative)\n",
    "\n",
    "\n",
    "# https://github.com/maciejkula/triplet_recommendations_keras/blob/master/triplet_keras.ipynb\n",
    "# https://www.kaggle.com/kmader/image-similarity-with-siamese-networks\n",
    "# https://github.com/keras-team/keras/issues/9498\n",
    "# https://github.com/keras-team/keras/issues/3921#issuecomment-250643688\n",
    "# \n",
    "\n",
    "# NOTE: layers.merge is deprecated. \n",
    "# the only way to do it now is custom keras layer which implements the triplet loss.\n",
    "# Create a loss layer\n",
    "# loss = layers.merge([embedding_a, embedding_p, embedding_n], \n",
    "#                     mode=triplet_loss, \n",
    "#                     name='loss',)\n",
    "\n",
    "\n",
    "# Write a custom layer for loss function.\n",
    "# loss = layers.triplet_loss([embedding_a, embedding_p, embedding_n])\n",
    "\n",
    "embedding_concat = layers.concatenate(inputs=[embedding_a, \n",
    "                                    embedding_p, \n",
    "                                    embedding_n], axis=-1)\n",
    "\n",
    "loss_layer = layers.Lambda(function=triplet_loss, \n",
    "                     output_shape=(1,))\n",
    "\n",
    "loss = loss_layer(embedding_concat)\n",
    "\n",
    "siamese_model = Model(input=[input_anchor, input_positive, input_negative], \n",
    "                      output=loss)\n",
    "\n",
    "siamese_model.compile(loss=identity_loss, optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 28, 84, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 28, 84, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 28, 84, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_model (Model)         (None, 128)          4627264     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384)          0           embedding_model[4][0]            \n",
      "                                                                 embedding_model[5][0]            \n",
      "                                                                 embedding_model[6][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,627,264\n",
      "Trainable params: 4,626,560\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 31.2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15ef2826fd0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.fit(x=[X_1_train, X_2_train, X_3_train], y=y_train, batch_size=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.563533935546875"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.evaluate(x=[X_1_test, X_2_test, X_3_test], y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
