# Perfect Forgery

Our initial project proposal consisted of two distinct parts:
1. Creating an LSTM to generate handwriting in a someone’s particular style
2. Create another model that would label “handwritten” text as authentic or generated by a computer
Due to technical difficulties in the first part, which will be explored below, this section became an analysis of the best pre-existing tools for handwriting synthesis. The second part remained the same but without our own generated data we found a forgery dataset online.

## Handwriting Synthesis

Handwriting synthesis is a recent field of study in machine learning. The problem consists of two parts: 

1. Parsing input handwritten text to extract author’s style

2. Synthesize new handwritten text based on the extracted style

Generating handwriting is not a new problem in computer science as there is a paper from 1996  that details a technique to generate handwriting without the use of machine learning [1]. This program simply spliced up input images of handwritten text into glyphs, such as the letter combination “th”, which were then strung together to create new text. Obviously this doesn’t work well for generating text that the program hasn’t seen before, and does a bad job of capturing the author’s style. Below we will explore current machine learning techniques and their individual strengths and weaknesses. 

TODO: INSERT IMAGE OF PROBLEM HERE

## What features make handwriting styles unique?

The ability to extract an author’s style from handwritten text proves a difficult problem to this day. Everyone has a unique style that is made up of many different variables such as spacing between letters, whether letters are connected or not (called ligatures), size of letters, and so on. It is important to note that these are not static features and all vary greatly between handwritten samples by the same author, so handwriting can be thought of as many distributions of independent features stacked on top of each other. Furthermore, handwriting needs to be evaluated at the character level and then the word level otherwise certain features such as ligatures will be lost. Therefore, it is very hard to identify what exactly makes a handwriting style unique, in one paper about attempting to identify authors from handwritten text researchers found their technique could not identify individual authors in a dataset of around 4,000 words but could simply groups words into classes of similar families of styles [2]. Note that depending on which language you are using and the dataset it may be possible to identify authors.

Therefore, to extract style from handwritten text there are only a few techniques available. These techniques depend on the way the handwritten text is represented as data, which in turn determines how style is represented.

## How is handwritten text represented?

There are two ways that handwritten text can be used in machine learning projects, either online or offline. Offline handwritten text are images (or pixel array values) of pictures or scans of handwritten text. This is the most abundant form of handwritten data, as a picture can be taken of any handwritten text, and therefore we can use historical documents or manuscripts with this representation. Online handwriting is the capturing of pen strokes as someone writes typically using a smart whiteboard or tablet. This ends up being a series of pen strokes, and whether or not the pen lifted off of the page with each stroke. This representation is therefore limited to handwriting that was done on these devices and therefore is relatively rare compared to offline data. 

Offline handwritten data has the benefit of using historical documents which allows someone to say extract Abraham Lincoln’s style. However, as presented below it is hard to extract features from offline data. Figure 1 is a sample of offline data from the IAM online database which shows how offline data would be processed.

![](img/iam_example.PNG)

**Figure 1.** [Offline handwritten data from IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)

Since the data is represented as an image, it is converted to an array of pixel values, which makes it hard to extract style. It is not clear in figure 1 where the L ends and the e begins, or the e and t. Offline data also makes storing someone’s style difficult, do you store the average pixels that makeup a character and the variations for certain features, if this is the case, how do you determine which features will be relevant before processing. These issues make it hard to work with offline data.

Online handwriting data is rare to find, and since the author had to write on a tablet or whiteboard it typically is messier than their actual handwriting. Because of this, their style may not match with their actual handwriting style. However, compared to offline handwriting, online handwriting is much more meaningful for extracting unique features of handwriting, this is because it is represented as a series of pen strokes. Figure 2 shows the online handwritten text from the IAM offline database. Note that the characters should be connected as shown by the dots connecting them.

![](img/so_says_the_times.PNG)

**Figure 2.** [Pen Strokes representing online handwriting](https://github.com/sjvasquez/handwriting-synthesis/pull/14)

With online handwritten data it is simple to tell when one letter ends and the next begins as we have the discrete points that create each letter. Since data is also included about when the pen lifts up then more complex features such as real time handwriting generation can be done. Finally, since we have the (x,y) of each pen stroke then we can determine the “curviness” of each letter, where the ligatures connect each letter, the average distance between letters and so on.

Although this section seems like it’s leading to the conclusion that online handwritten data is better this is not necessarily the case as we will see in the following sections about each technique and what form of data it uses. Since offline handwritten data consists of historical documents it is more attractive to get a model working with it, as this can then be applied to all handwritten text ever, whereas online handwritten text requires the apparatus to record it. 

## Machine Learning with Handwriting

In this section we will explore the three general techniques we found while researching this topic and compare and contrast their strengths and weaknesses. We will discuss long short-term memory neural networks, generative adversarial networks, and dynamic programming with random forests. Each of these models uses different techniques to generate text, and we will explain how this influences the quality of generated text.

### LSTM

### GAN
Generative adversarial network (GAN) models are a machine learning technique that aims to automatically create the best output possible with the least effort from the programmer [3]. This is done by creating two neural networks that work together to automate the process of improving models. One neural network is the generator which outputs data which the other neural network, the discriminator, attempts to distinguish whether the data is computer-generated or not. The goal of the generator is to increase the error of the discimator by creating the most believable samples possible, this is done by backpropagating to each network after each classification by the discriminator.

Using a GAN to generate handwriting requires less data than other techniques which is a large benefit as other techniques take thousands of annotated samples to run [4]. The GAN we focus on here from Alonso et. al. [4] uses the Graves’ LSTM described above to preprocess data. This paper generates french and arabic letters, and is relatively complex. Before a series of characters is passed to the generator, it is encoded then preprocessed using a RNN with LSTM cells. This is then passed to the generator with random noise which creates handwritten text using a series of CNN layers. The data is then passed to the discriminator D which attempts to classify the writing as real or generated, and another discriminator R which attempts to recognize what word it is. The primary objective of the generator is create legible words so R attempts to recognize the output and compare it to the textual input. The generator uses an attention or window function which allows it shift through the encoded input and focus on one letter at a time with some focus on the letters before and after it.

The loss function for R is connectionist temporal classification (CTC) which is a loss function that compares two sequences with different sizes. For example the input may have different spacing than the output, but the output could still be correct, so CTC uses independent positioning and probability of next element to compare words which overcomes the challenges of normal loss functions. 

The loss function for D is a standard GAN loss which closely resembles cross-entropy loss as shown in figure 3. Here D(x) is the probability a discriminator thinks an output is real, Ex and Ez are the expected value over real inputs and all inputs (including noise). Finally D(G(z)) is the probability that the discriminator thinks a fake output is real.

![](img/gan_loss.PNG)

**Figure 3.** [Minimax GAN loss](https://developers.google.com/machine-learning/gan/loss)

GANs are new deep learning models so they are very complex. This model is great at creating realistic output with minimal data to train on however. Therefore, it is great for datasets with only a few samples for an author. It also uses offline handwriting.  Below is an example of a generated word that looks quite realistic, beneath it is another output that looks very off. In general these models have varying degrees of success. This is due to the fact that GANs attempt to convert input from the latent space into the output space, therefore the ability to write a perfect j is in the latent space but the network has to find it which is quite difficult given that it receives random noise as input also. In addition to this, this GAN works at the character level, and therefore has trouble generating realistic ligatures as seen in both examples below. The “ou” in “bonjour” looks off, and the “us” in “olibrius” has some weird artifact of a ligature remaining. 

![](img/bonjour.png)

**Figure 4.** The output of the GAN for the word “bonjour” 

![](img/olibrius.png)

**Figure 5.** The output of the GAN for the word “olibrius”

In summation, GANs are great for handwriting synthesis as they can use offline handwritten data, on top of that they fewer samples than other techniques to create authentic output. However, they have trouble creating realistic characters, as since they have to navigate the latent space they will rarely find the best character, and they have trouble generating ligatures between characters.

### Dynamic Programming with Random Forests

# References
1. *Guyon, I. (1996). Handwriting synthesis from handwritten glyphs. In Proceedings of the Fifth International Workshop on Frontiers of Handwriting Recognition (pp. 140-153).*

2. *Crettez, J. P. (1995, August). A set of handwriting families: style recognition. In Proceedings of 3rd International Conference on Document Analysis and Recognition (Vol. 1, pp. 489-494). IEEE.*

3. *Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).*

4. *Alonso, E., Moysset, B., & Messina, R. (2019). Adversarial Generation of Handwritten Text Images Conditioned on Sequences. arXiv preprint arXiv:1903.00277.*
