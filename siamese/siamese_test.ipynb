{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from scipy.misc import imresize\n",
    "# import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from matplotlib import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path = './Dataset/interim/real/'\n",
    "# new_directory = './Dataset/preprocessed/real'\n",
    "# # directory_path = './Dataset/interim/forged/'\n",
    "# # new_directory = './Dataset/preprocessed/forged'\n",
    "# for filename in listdir(directory_path):\n",
    "#     # load image\n",
    "#     image = Image.open(directory_path + '/' + filename)\n",
    "#     # resize image and ignore original aspect ratio\n",
    "#     img_resized = image.resize((200,200))\n",
    "#     gs_image = img_resized.convert(mode='L')\n",
    "#     # save\n",
    "#     gs_image.save(new_directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = glob.glob('./Dataset/preprocessed/real/*.png')\n",
    "forged_images = glob.glob('./Dataset/preprocessed/forged/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_id(image_path):\n",
    "    \"\"\"returns image ID from the image path\"\"\"\n",
    "    image_id = image_path.split('/')[-1].split('_')[0]\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store all images.\n",
    "real_images_dict = defaultdict(list)\n",
    "forged_images_dict = defaultdict(list)\n",
    "\n",
    "# Iterate over real images and put them in dictionary values for same image_id key.\n",
    "for real_image, forged_image in zip(real_images, forged_images):\n",
    "    \n",
    "    # add image to dictionary\n",
    "    real_image_id = get_image_id(real_image)\n",
    "    real_images_dict[real_image_id].append(real_image)\n",
    "    \n",
    "    forged_image_id = get_image_id(forged_image)\n",
    "    forged_images_dict[forged_image_id].append(forged_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tuples of image for training\n",
    "negative_image_tuples = list()\n",
    "# positive_image_tuples = list()\n",
    "\n",
    "for image_id in real_images_dict.keys():\n",
    "    real = real_images_dict[image_id]\n",
    "    forged = forged_images_dict[image_id]\n",
    "    \n",
    "    negative_image_tuples.extend(list(itertools.product(real, real, forged)))\n",
    "#     positive_image_tuples.extend(list(itertools.product(real, real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image_path, size=(200, 220)):\n",
    "    \"\"\"returns processed images\"\"\"\n",
    "    # Open image and convert to grayscale.\n",
    "    image = Image.open(image_path)\n",
    "    # image = image.convert(\"L\")\n",
    "    \n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Resize image to 128, 256 using bilinear interpolation.\n",
    "    # image_array_processed = imresize(image_array, size=size, interp='bilinear')\n",
    "    \n",
    "    # Invert pixel values.\n",
    "    image_array_processed = 1 - image_array\n",
    "    \n",
    "    # Normalize by dividing pixel values with standard deviation.\n",
    "    image_array_processed = image_array_processed / np.std(image_array_processed)\n",
    "    \n",
    "    # Expand dimension to (200, 220, 1)\n",
    "    image_array_processed = np.expand_dims(image_array_processed, axis=2)\n",
    "    \n",
    "    return image_array_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data\n",
    "image_1 = []\n",
    "image_2 = []\n",
    "image_3 = []\n",
    "labels = []\n",
    "\n",
    "for anchor, positive, negative in negative_image_tuples[:1000]:\n",
    "    image_1.append(process(anchor))\n",
    "    image_2.append(process(positive))\n",
    "    image_3.append(process(negative))\n",
    "    labels.append(0)\n",
    "    \n",
    "# for real1, real2 in positive_image_tuples:\n",
    "#     image_1.append(process(real1))\n",
    "#     image_2.append(process(real2))\n",
    "#     labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "image_1_array = np.asarray(image_1)\n",
    "image_2_array = np.asarray(image_2)\n",
    "image_3_array = np.asarray(image_3)\n",
    "labels_array = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle numpy arrays\n",
    "idx = np.random.choice(range(len(image_1)), size=len(image_1), replace=False)\n",
    "\n",
    "X_1 = image_1_array[idx]\n",
    "X_2 = image_2_array[idx]\n",
    "X_3 = image_3_array[idx]\n",
    "y = labels_array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-valid-test set.\n",
    "train_split = 0.8\n",
    "valid_split = 0.9\n",
    "train_offset = int(train_split * len(X_1))\n",
    "valid_offset = int(valid_split * len(X_1))\n",
    "\n",
    "X_1_train = X_1[:train_offset]\n",
    "X_2_train = X_2[:train_offset]\n",
    "X_3_train = X_3[:train_offset]\n",
    "y_train = y[:train_offset]\n",
    "\n",
    "X_1_valid = X_1[train_offset:valid_offset]\n",
    "X_2_valid = X_2[train_offset:valid_offset]\n",
    "X_3_valid = X_3[train_offset:valid_offset]\n",
    "y_valid = y[train_offset:valid_offset]\n",
    "\n",
    "X_1_test = X_1[valid_offset:]\n",
    "X_2_test = X_2[valid_offset:]\n",
    "X_3_test = X_3[valid_offset:]\n",
    "y_test = y[valid_offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 200, 200, 1), (100, 200, 200, 1), (100, 200, 200, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train.shape, y_valid.shape, y_test.shape\n",
    "X_1_train.shape, X_1_valid.shape, X_1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "destn_dir = './Dataset/saved_processed/'\n",
    "np.savez(os.path.join(destn_dir, 'train.npz'), X_1_train=X_1_train, X_2_train=X_2_train, X_3_train=X_3_train, y_train=y_train)\n",
    "np.savez(os.path.join(destn_dir, 'valid.npz'), X_1_valid=X_1_valid, X_2_valid=X_2_valid, X_3_valid=X_3_valid, y_valid=y_valid)\n",
    "np.savez(os.path.join(destn_dir, 'test.npz'), X_1_test=X_1_test, X_2_test=X_2_test, X_3_test=X_3_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forgery prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Dataset/saved_processed/'\n",
    "\n",
    "train = np.load(os.path.join(data_path, 'train.npz'))\n",
    "X_1_train=train['X_1_train']\n",
    "X_2_train=train['X_2_train']\n",
    "X_3_train=train['X_3_train']\n",
    "y_train=train['y_train']\n",
    "\n",
    "valid = np.load(os.path.join(data_path, 'valid.npz'))\n",
    "X_1_valid=valid['X_1_valid']\n",
    "X_2_valid=valid['X_2_valid']\n",
    "X_3_valid=valid['X_3_valid']\n",
    "y_valid=valid['y_valid']\n",
    "\n",
    "test = np.load(os.path.join(data_path, 'test.npz'))\n",
    "X_1_test=test['X_1_test']\n",
    "X_2_test=test['X_2_test']\n",
    "X_3_test=test['X_3_test']\n",
    "y_test=test['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 2\n",
    "input_shape = (200, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "800/800 [==============================] - 80s 100ms/step - loss: 0.1522 - accuracy: 0.9100 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "800/800 [==============================] - 77s 96ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_2_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_2_valid, y_valid))\n",
    "score = model.evaluate(X_2_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 190, 190, 96)      11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 190, 190, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 94, 94, 96)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 98, 98, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 94, 94, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 94, 94, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 48, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 384)       885120    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 48, 48, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 46, 46, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              126878720 \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 129,407,808\n",
      "Trainable params: 129,407,104\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputTensor = Input((200,200,1))\n",
    "\n",
    "conv1 = layers.Conv2D(filters=96, \n",
    "                      kernel_size=(11,11), \n",
    "                      strides=1, \n",
    "                      activation='relu', \n",
    "                      input_shape=(155, 220, 1), \n",
    "                      data_format=\"channels_last\")(inputTensor)\n",
    "\n",
    "conv1_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv1)\n",
    "\n",
    "conv1_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv1_norm)\n",
    "\n",
    "conv2_padding = layers.ZeroPadding2D((2, 2))(conv1_pool)\n",
    "\n",
    "conv2 = layers.Conv2D(filters=256, \n",
    "                      kernel_size=(5,5), \n",
    "                      strides=1, \n",
    "                      activation='relu')(conv2_padding)\n",
    "\n",
    "conv2_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv2)\n",
    "\n",
    "conv2_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv2_norm)\n",
    "\n",
    "conv2_dropout = layers.Dropout(0.3, seed=1)(conv2_pool)\n",
    "\n",
    "conv3_padding = layers.ZeroPadding2D((1,1))(conv2_dropout)\n",
    "\n",
    "conv3 = layers.Conv2D(filters=384, \n",
    "                      kernel_size=(3,3), \n",
    "                      strides=1, \n",
    "                      activation = 'relu')(conv3_padding)\n",
    "\n",
    "conv4_padding = layers.ZeroPadding2D((1,1))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(filters=256, \n",
    "                      kernel_size=(3,3), \n",
    "                      strides=1, \n",
    "                      activation='relu')(conv4_padding)\n",
    "                                                                    \n",
    "conv4_pool = layers.MaxPooling2D(pool_size=(3,3), \n",
    "                                 strides=2)(conv4)\n",
    "                                                                    \n",
    "conv4_dropout = layers.Dropout(0.3, seed=1)(conv4_pool)\n",
    "                                                                    \n",
    "flatten_layer = layers.Flatten()(conv4_dropout)\n",
    "                                                                    \n",
    "fully_connected1 = layers.Dense(1024)(flatten_layer)\n",
    "\n",
    "fc1_dropout = layers.Dropout(0.5, seed=1)(fully_connected1)\n",
    "                                                                    \n",
    "embedding = layers.Dense(128)(fc1_dropout)\n",
    "                                                                    \n",
    "embedding_model = Model(inputs=[inputTensor], \n",
    "                         outputs=embedding, \n",
    "                         name='embedding_model')\n",
    "                                                                    \n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(embeddings):\n",
    "    \"\"\"\n",
    "    calculates triplet loss over inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_a, processed_p, processed_n = embeddings[0], embeddings[1], embeddings[2]\n",
    "    \n",
    "    positive_dist= euclidean_distance_loss(processed_a, processed_p)\n",
    "    negative_dist = euclidean_distance_loss(processed_a, processed_n)\n",
    "       \n",
    "    margin = 0.0\n",
    "    loss = K.maximum(margin, positive_dist - negative_dist)\n",
    "    \n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fake loss function for Keras.\n",
    "    \"\"\"\n",
    "    return y_pred - 0 * y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huamingsun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "# Siamese model\n",
    "\n",
    "in_dim=(200,200,1)\n",
    "input_anchor = Input(shape=(in_dim))\n",
    "input_positive = Input(shape=(in_dim))\n",
    "input_negative = Input(shape=(in_dim))\n",
    "embedding_a=embedding_model(input_anchor)\n",
    "embedding_p=embedding_model(input_positive)\n",
    "embedding_n=embedding_model(input_negative)\n",
    "\n",
    "\n",
    "# https://github.com/maciejkula/triplet_recommendations_keras/blob/master/triplet_keras.ipynb\n",
    "# https://www.kaggle.com/kmader/image-similarity-with-siamese-networks\n",
    "# https://github.com/keras-team/keras/issues/9498\n",
    "# https://github.com/keras-team/keras/issues/3921#issuecomment-250643688\n",
    "# \n",
    "\n",
    "# NOTE: layers.merge is deprecated. \n",
    "# the only way to do it now is custom keras layer which implements the triplet loss.\n",
    "# Create a loss layer\n",
    "# loss = layers.merge([embedding_a, embedding_p, embedding_n], \n",
    "#                     mode=triplet_loss, \n",
    "#                     name='loss',)\n",
    "\n",
    "\n",
    "# Write a custom layer for loss function.\n",
    "# loss = layers.triplet_loss([embedding_a, embedding_p, embedding_n])\n",
    "\n",
    "embedding_concat = layers.concatenate(inputs=[embedding_a, \n",
    "                                    embedding_p, \n",
    "                                    embedding_n], axis=-1)\n",
    "\n",
    "loss_layer = layers.Lambda(function=triplet_loss, \n",
    "                     output_shape=(1,))\n",
    "\n",
    "loss = loss_layer(embedding_concat)\n",
    "\n",
    "siamese_model = Model(input=[input_anchor, input_positive, input_negative], \n",
    "                      output=loss)\n",
    "\n",
    "siamese_model.compile(loss=identity_loss, optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_model (Model)         (None, 128)          129407808   input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           embedding_model[1][0]            \n",
      "                                                                 embedding_model[2][0]            \n",
      "                                                                 embedding_model[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 129,407,808\n",
      "Trainable params: 129,407,104\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huamingsun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2078s 3s/step - loss: 1683.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a249bd4a8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.fit(x=[X_1_train, X_2_train, X_3_train], y=y_train, batch_size=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 35s 354ms/step\n"
     ]
    }
   ],
   "source": [
    "siamese_model.evaluate(x=[X_1_test, X_2_test, X_3_test], y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
